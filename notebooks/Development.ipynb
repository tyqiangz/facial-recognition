{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import face_recognition\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def get_face_image(image_filepath, convert_numpy=True):\n",
    "    '''\n",
    "    Obtain an image such that the image contains only 1 face.\n",
    "    If no face(s) can be found, return `None`.\n",
    "    \n",
    "    :param image_filepath: filepath to the image\n",
    "    :type image_filepath: str\n",
    "    \n",
    "    :param convert_numpy: to convert the face images to numpy data type or not\n",
    "    :type convert_numpy: bool\n",
    "    \n",
    "    :return face_image: \n",
    "        1. if convert_numpy=False:\n",
    "            a tensor object representing the face, should have dimensions\n",
    "            `[num_of_channels, height, width]`, with float values ranging from -1 to 1.\n",
    "        2. if convert_numpy=True:\n",
    "            a numpy.ndaarray representing the face, should have dimensions\n",
    "            `[height, width, num_of_channels]`, with int values ranging from 0 to 255.\n",
    "    :rtype face_image: torch.Tensor or numpy.ndarray\n",
    "    '''\n",
    "    image = Image.open(image_filepath).convert(\"RGB\")\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # for detecting face(s), only at most 1 face will be returned, \n",
    "    # the area of the image that is most probably a face is returned\n",
    "    mtcnn = MTCNN(\n",
    "        image_size=200, margin=0, min_face_size=50,\n",
    "        select_largest=False, keep_all=False, device=device\n",
    "    )\n",
    "\n",
    "    face_tensor_image = mtcnn(image)\n",
    "\n",
    "    # if no faces are detected, `None` value is returned\n",
    "    if face_tensor_image is None:\n",
    "        return None\n",
    "    \n",
    "    if convert_numpy:\n",
    "        # convert the tensor image to RGB valued image in numpy \n",
    "        face_image = np.array(((face_tensor_image+1)/2 * 255).permute(1, 2, 0), dtype='uint8')\n",
    "    else:\n",
    "        face_image = face_tensor_image\n",
    "        \n",
    "    return face_image\n",
    "\n",
    "def get_face_landmarks(image_filepath):\n",
    "    '''\n",
    "    Return the facial landmarks if at least one face is found in `image_path`.\n",
    "    \n",
    "    :param image_filepath: filepath to an image\n",
    "    :type image_filepath: str\n",
    "    \n",
    "    :return face_landmarks: a dictionary of face landmark and the coordinates\n",
    "    :rtype face_landmarks: dict\n",
    "    \n",
    "    :return face_image: an image that corresponds to the face in which landmarks are extracted\n",
    "    :rtype face_image: numpy.ndarray\n",
    "    '''\n",
    "    \n",
    "    face_image = get_face_image(image_filepath, convert_numpy=True)\n",
    "    \n",
    "    # if more than 1 face is detected or no face is detected, `None` values are returned\n",
    "    if face_image is None:\n",
    "        return None, None\n",
    "\n",
    "    # obtain coordinates of the facial features, `chin`, `eyes` etc\n",
    "    face_landmarks_list = face_recognition.face_landmarks(face_image, model='large')\n",
    "\n",
    "    # if no facial features are detected or more than 1 set of facial features are detected, \n",
    "    # `None` values are returned\n",
    "    if len(face_landmarks_list) != 1:\n",
    "        return None, None\n",
    "\n",
    "    face_landmarks = face_landmarks_list[0]\n",
    "\n",
    "    return face_landmarks, face_image\n",
    "\n",
    "def get_face_embedding(image_filepath):\n",
    "    '''\n",
    "    Compute an face embedding for an image containing face.\n",
    "    If one or more faces are found in the image, the area of the image \n",
    "    that has the highest probability of being a face is returned.\n",
    "\n",
    "    :param image_filepath: filepath to image\n",
    "    :type image_filepath: str\n",
    "\n",
    "    :return embedding: a vector representing the face\n",
    "    :rtype embedding: numpy.ndarray\n",
    "    '''\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # for generating embeddings for a face image\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "    # detect faces\n",
    "    face_image = get_face_image(image_filepath, convert_numpy=False)\n",
    "\n",
    "    # if no faces are detected\n",
    "    if face_image is None:\n",
    "        embedding = None\n",
    "    else:\n",
    "        # add one more dimension to the tensors as the resnet takes in a tensor of dimension 4\n",
    "        # `(num_img, num_channels, width, height)`\n",
    "        face_images = torch.unsqueeze(face_image, dim=0)\n",
    "\n",
    "        # obtain face embedding\n",
    "        embedding = resnet(face_images).detach().cpu()[0].numpy()\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def get_skin_colours(image_filepath):\n",
    "    '''\n",
    "    Given an image, location of the face and face landmarks,\n",
    "    extract out the left and right eyes, top and bottom lips.\n",
    "    \n",
    "    :param image_filepath: filepath to image\n",
    "    :type image_filepath: str\n",
    "    \n",
    "    :return skin_colours: rgb values of the pixels identified as the skin\n",
    "    :rtype skin_colours: numpy.ndarray\n",
    "    \n",
    "    :return skin_img: an image showing only the skin, the rest of the non-skin areas of the \n",
    "        image are in white.\n",
    "    :rtype skin_img: PIL.Image.Image\n",
    "    '''\n",
    "    \n",
    "    # try obtaining facial landmarks using facenet\n",
    "    face_landmarks, face_image = get_face_landmarks(image_filepath)\n",
    "\n",
    "    if face_landmarks is None:\n",
    "        return None, None\n",
    "    \n",
    "    else:\n",
    "        image = Image.fromarray(face_image).convert(\"RGBA\")\n",
    "        \n",
    "        # convert to numpy (for convenience)\n",
    "        imArray = np.asarray(image)\n",
    "\n",
    "        ##################### retain face area only ####################\n",
    "        # create mask full of ones, essentially an image with zero-values\n",
    "        maskIm = Image.new('L', (imArray.shape[1], imArray.shape[0]), 0)\n",
    "\n",
    "        d = ImageDraw.Draw(maskIm)\n",
    "\n",
    "        # extract only the face\n",
    "        d.polygon(face_landmarks['chin'], outline=1, fill=1)\n",
    "\n",
    "        # obtain the pixel values from the PIL image\n",
    "        mask = np.array(maskIm)\n",
    "\n",
    "        # assemble new image (uint8: 0-255)\n",
    "        newImArray = np.empty(imArray.shape,dtype='uint8')\n",
    "\n",
    "        # colors (three first columns, RGB)\n",
    "        newImArray[:,:,:3] = imArray[:,:,:3]\n",
    "\n",
    "        # transparency (4th column)\n",
    "        newImArray[:,:,3] = mask*255\n",
    "\n",
    "        ##################### remove face landmarks ####################\n",
    "        # create mask full of ones    \n",
    "        d = ImageDraw.Draw(maskIm)\n",
    "\n",
    "        # for each facial landmark ...\n",
    "        for face_landmark in face_landmarks:\n",
    "            # do not remove the chin area\n",
    "            if face_landmark == 'chin':\n",
    "                continue\n",
    "\n",
    "            # create a polygon full of zeros wihtin the mask of ones\n",
    "            polygon = face_landmarks[face_landmark]\n",
    "            d.polygon(polygon, outline=0, fill=0)\n",
    "\n",
    "        # obtain the pixel values from the PIL image\n",
    "        mask = np.array(maskIm)\n",
    "\n",
    "        # assemble new image (uint8: 0-255)\n",
    "        finalImArray = np.empty(newImArray.shape,dtype='uint8')\n",
    "\n",
    "        # colors (three first columns, RGB)\n",
    "        finalImArray[:,:,:3] = newImArray[:,:,:3]\n",
    "\n",
    "        # transparency (4th column)\n",
    "        finalImArray[:,:,3] = mask*255\n",
    "\n",
    "        # back to Image from numpy\n",
    "        skin_img = Image.fromarray(finalImArray, \"RGBA\")\n",
    "\n",
    "        ################### extract skin colours ###################\n",
    "        skin_colours = []\n",
    "        pixel_values = np.asarray(skin_img)\n",
    "\n",
    "        height, width, channels = pixel_values.shape\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                colour = pixel_values[i][j]\n",
    "\n",
    "                if colour[3] != 0:\n",
    "                    skin_colours.append(colour[:3])\n",
    "\n",
    "        skin_colours = np.asarray(skin_colours)\n",
    "\n",
    "        return skin_colours, skin_img\n",
    "    \n",
    "def _get_skin_tones(skin_rgb, method='median', num_tones=2):\n",
    "    '''\n",
    "    Extract the skin tone (RGB values) from a list of RGB values of the skin.\n",
    "    \n",
    "    :param skin_rgb: an array of RGB values of skin\n",
    "    :type skin_rgb: numpy.ndarray\n",
    "    \n",
    "    :param method: the method to extract the skin tones\n",
    "    :type method: str\n",
    "    \n",
    "    :param num_tones: number of top skin tones to extract, only applicable if \n",
    "        `method = 'knn'`\n",
    "    :type num_tones: int\n",
    "    \n",
    "    :return skin_tones: the RGB value(s) of the skin tone of the input skin rgb\n",
    "        dimension `(num_tones, 3)`.\n",
    "    :rtype skin_tones: numpy.ndarray\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    >>> skin_rgb = np.array([[148, 128, 121],\n",
    "                             [144, 124, 117],\n",
    "                             [142, 121, 116],\n",
    "                             [106,  75,  73],\n",
    "                             [106,  75,  73],\n",
    "                             [111,  81,  83]])\n",
    "    >>> get_skin_tone(skin_rgb, method='knn', num_tones=2)\n",
    "    \n",
    "    [[107,  77,  76],\n",
    "     [144, 124, 118]]\n",
    "     \n",
    "    >>> skin_rgb = np.array([[148, 128, 121],\n",
    "                             [144, 124, 117],\n",
    "                             [142, 121, 116],\n",
    "                             [106,  75,  73],\n",
    "                             [106,  75,  73],\n",
    "                             [111,  81,  83]])\n",
    "    >>> get_skin_tone(skin_rgb, method='median', num_tones=2)\n",
    "    \n",
    "    [[126, 101,  99]]\n",
    "    ```\n",
    "    '''\n",
    "    \n",
    "    # mean of the rgb values\n",
    "    if method == 'mean':\n",
    "        skin_tone = np.asarray(np.mean(skin_rgb, axis=0), dtype=int)\n",
    "        \n",
    "        # make it an array of array for consistency of return type\n",
    "        skin_tones = np.array([skin_tone])\n",
    "        return skin_tones\n",
    "    \n",
    "    # median of the rgb values\n",
    "    elif method == 'median':\n",
    "        skin_tone = np.asarray(np.median(skin_rgb, axis=0), dtype=int)\n",
    "        # make it an array of array for consistency of return type\n",
    "        skin_tones = np.array([skin_tone])\n",
    "        return skin_tones\n",
    "    \n",
    "    # K nearest neighbours of the rgb values\n",
    "    elif method == 'knn':\n",
    "        skin_clusters = KMeans(n_clusters=num_tones, random_state=42).fit(skin_rgb)\n",
    "        skin_tones = np.array(skin_clusters.cluster_centers_, dtype=int)\n",
    "        return skin_tones\n",
    "    else:\n",
    "        raise ValueError('Please specify a valid method to extract skin tone.')\n",
    "        \n",
    "def get_skin_tones(image_filepath, method='knn', num_tones=2):\n",
    "    '''\n",
    "    Extract the skin tone (RGB values) from an image containing at least one face.\n",
    "    \n",
    "    :param image_filepath: filepath to image\n",
    "    :type image_filepath: str\n",
    "    \n",
    "    :param method: the method to extract the skin tones\n",
    "    :type method: str\n",
    "    \n",
    "    :param num_tones: number of top skin tones to extract, only applicable if \n",
    "        `method = 'knn'`\n",
    "    :type num_tones: int\n",
    "    \n",
    "    :return skin_tones: the RGB value(s) of the skin tone of the input skin rgb\n",
    "        dimension `(num_tones, 3)`.\n",
    "    :rtype skin_tones: numpy.ndarray\n",
    "    \n",
    "    :return skin_img: an image showing only the skin, the rest of the non-skin areas of the \n",
    "        image are in white.\n",
    "    :rtype skin_img: PIL.Image.Image\n",
    "    '''\n",
    "    skin_colours, skin_img = get_skin_colours(image_filepath)\n",
    "    \n",
    "    if skin_colours is None:\n",
    "        skin_tones = None\n",
    "    else:\n",
    "        skin_tones = _get_skin_tones(skin_colours, method=method, num_tones=num_tones)\n",
    "    \n",
    "    return skin_tones, skin_img\n",
    "\n",
    "def distance(embeddings1, embeddings2, distance_metric='cosine'):\n",
    "    '''\n",
    "    Distance metric for 2 embedding vectors.\n",
    "    \n",
    "    :param embeddings1: first embedding, shape of 1 x N\n",
    "    :type embeddings1: numpy.ndarray\n",
    "\n",
    "    :param embeddings2: second embedding, shape of 1 x N\n",
    "    :type embeddings2: numpy.ndarray\n",
    "    \n",
    "    :param distance_metric: the distance metric to use to compare similarity\n",
    "        between two embedding vectors.\n",
    "    :type distance_metric: str\n",
    "    \n",
    "    :return dist: distance between the embedding vectors based on the selected distance metric\n",
    "    :rtype dist: float\n",
    "    '''\n",
    "    \n",
    "    if distance_metric=='euclidean':\n",
    "        # Euclidian distance\n",
    "        dist = np.linalg.norm(embeddings1 - embeddings2)\n",
    "    \n",
    "    elif distance_metric=='cosine':\n",
    "        # Distance based on cosine similarity\n",
    "        dot = np.sum(np.multiply(embeddings1, embeddings2))\n",
    "        norm = np.linalg.norm(embeddings1) * np.linalg.norm(embeddings2)\n",
    "        similarity = dot / norm\n",
    "        \n",
    "        # to round down for round-off errors where `similarity = 1.00001`\n",
    "        if similarity > 1:\n",
    "            similarity = 1\n",
    "        if similarity < -1:\n",
    "            similarity = -1\n",
    "        \n",
    "        dist = np.arccos(similarity) / math.pi\n",
    "    else:\n",
    "        raise f\"Undefined distance metric: {distance_metric}\"\n",
    "\n",
    "    return dist\n",
    "\n",
    "def _get_face_similarity(embedding_1, embedding_2):\n",
    "    '''\n",
    "    Compute a similarity score of 2 face embedding\n",
    "    1 being exactly the same face, 0 being totally different.\n",
    "\n",
    "    `None` will be returned if either of the images do not \n",
    "    contain at least one face.\n",
    "\n",
    "    :param embedding_1: embedding vector of face 1\n",
    "    :type embedding_1: numpy.ndarray\n",
    "\n",
    "    :param embedding_2: embedding vector of face 1\n",
    "    :type embedding_2: numpy.ndarray\n",
    "\n",
    "    :return face_similarity: a similarity score of the faces in the images given.\n",
    "    :rtype face_similarity: `float` if exactly 1 face is detected in each image, else `None`.\n",
    "    '''\n",
    "    \n",
    "    if embedding_1 is None or embedding_2 is None:\n",
    "        return None\n",
    "\n",
    "    face_similarity = 1 - distance(embedding_1, embedding_2, distance_metric='cosine')\n",
    "    return face_similarity\n",
    "\n",
    "def get_face_similarity(image_path_1, image_path_2):\n",
    "    '''\n",
    "    Compute a similarity score of the faces in 2 images.\n",
    "    1 being exactly the same face, 0 being totally different.\n",
    "\n",
    "    `None` will be returned if either of the images do not \n",
    "    contain exactly one face.\n",
    "\n",
    "    :param image_path_1: filepath to 1st image\n",
    "    :type image_path_1: str\n",
    "\n",
    "    :param image_path_2: filepath to 2nd image\n",
    "    :type image_path_2: str\n",
    "\n",
    "    :param method: the method used to detect faces, \n",
    "        `method = \"dlib\"` is faster but less accurate,\n",
    "        `method = \"facenet\"` is more accurate but slower .\n",
    "    :type method: str\n",
    "\n",
    "    :return face_similarity: a similarity score of the faces in the images given.\n",
    "    :rtype face_similarity: `float` if exactly 1 face is detected in each image, else `None`.\n",
    "    '''\n",
    "    \n",
    "    embedding_1 = get_face_embedding(image_path_1)\n",
    "    embedding_2 = get_face_embedding(image_path_2)\n",
    "\n",
    "    face_similarity = _get_face_similarity(embedding_1, embedding_2)\n",
    "    \n",
    "    return face_similarity\n",
    "\n",
    "def _get_skin_tone_similarity(skin_tones_1, skin_tones_2, method=\"mean\"):\n",
    "    '''\n",
    "    Obtain the percentage similarity between 2 skin tones.\n",
    "    A score between 0 to 1 is returned, 0 meaning totally dissimilar,\n",
    "    1 meaning exactly the same.\n",
    "    \n",
    "    A research paper about the best distance metric of two skin rgb values can be found in: \n",
    "    http://dx.doi.org/10.5121/csit.2013.3210.\n",
    "    \n",
    "    :param skin_tones_1: rgb value(s) of skin tone 1 with dimension `(num_skin_tones, 3)`\n",
    "    :type skin_tones_1: numpy.ndarray\n",
    "    \n",
    "    :param skin_tones_2: rgb value(s) of skin tone 2 with dimension `(num_skin_tones, 3)`\n",
    "    :type skin_tones_2: numpy.ndarray\n",
    "    \n",
    "    :return skin_tone_similarity: percentage similarity between 2 skin tones\n",
    "    :rtype skin_tone_similarity: float\n",
    "    '''\n",
    "    \n",
    "    assert skin_tones_1.shape == skin_tones_2.shape\n",
    "    num_skin_tones = len(skin_tones_1)\n",
    "    \n",
    "    skin_tone_similarities_sum = 0\n",
    "    \n",
    "    for i in range(num_skin_tones):\n",
    "        abs_diff = np.abs(skin_tones_1[i] - skin_tones_2[i])\n",
    "        skin_tone_similarities_sum += 1 - np.mean(abs_diff / 255)\n",
    "    \n",
    "    skin_tone_similarity = skin_tone_similarities_sum / num_skin_tones\n",
    "    \n",
    "    return skin_tone_similarity\n",
    "\n",
    "def get_skin_tone_similarity(image_filepath_1, image_filepath_2):\n",
    "    '''\n",
    "    Obtain the percentage similarity between 2 skin tones from 2 images.\n",
    "    \n",
    "    If exactly 1 face is found in each image, a score between 0 to 1 is returned, \n",
    "    0 meaning totally dissimilar, 1 meaning exactly the same;\n",
    "    else, return None\n",
    "    \n",
    "    :param image_path_1: filepath to the first image\n",
    "    :type image_path_1: str\n",
    "    \n",
    "    :param image_path_2: filepath to the second image\n",
    "    :type image_path_2: str\n",
    "    \n",
    "    :return skin_tone_similarity: percentage similarity between 2 skin tones\n",
    "    :rtype skin_tone_similarity: float\n",
    "    \n",
    "    :return skin_1: an image showing only the skin of `image_path_1`, \n",
    "        the rest of the non-skin areas of the image are in white.\n",
    "    :rtype skin_1: PIL.Image.Image\n",
    "    \n",
    "    :return skin_2: an image showing only the skin of `image_path_2`, \n",
    "        the rest of the non-skin areas of the image are in white.\n",
    "    :rtype skin_2: PIL.Image.Image\n",
    "    \n",
    "    :return skin_tones_1: rgb values of skin tones of `image_path_1`\n",
    "    :rtype skin_tones_1: numpy.ndarray\n",
    "    \n",
    "    :return skin_tones_2: rgb values of skin tones of `image_path_2`\n",
    "    :rtype skin_tones_2: numpy.ndarray\n",
    "    '''\n",
    "    \n",
    "    skin_tones_1, skin_1 = get_skin_tones(image_filepath_1, method='knn', num_tones=2)\n",
    "    skin_tones_2, skin_2 = get_skin_tones(image_filepath_2, method='knn', num_tones=2)\n",
    "    \n",
    "    skin_tone_similarity = _get_skin_tone_similarity(skin_tones_1, skin_tones_2)\n",
    "    \n",
    "    return skin_tone_similarity, skin_1, skin_2, skin_tones_1, skin_tones_2\n",
    "\n",
    "def hash_image(image_filepath):\n",
    "    '''\n",
    "    Generate a unique identifier of an image.\n",
    "\n",
    "    :param filepath_to_image: filepath to the image to be hashed\n",
    "    :type filepath_to_image: str\n",
    "\n",
    "    :return hash_of_image: a sha256 hash of the image\n",
    "    :rtype hash_of_image: str\n",
    "    '''\n",
    "    \n",
    "    image = Image.open(image_filepath).convert(\"RGB\")\n",
    "    image_array = np.asarray(image)\n",
    "    image_bytes = image_array.data.tobytes()\n",
    "    \n",
    "    hash_of_image = hashlib.sha256(image_bytes).hexdigest()\n",
    "        \n",
    "    return hash_of_image\n",
    "\n",
    "def store_face_features_single(pickle_filepath, image_filepath):\n",
    "    '''\n",
    "    Store the facial features in the image at the given filepath.\n",
    "    \n",
    "    :param pickle_filepath: filepath to the pickle file that stores the facial features\n",
    "    :type pickle_filepath: str\n",
    "    \n",
    "    :param image_filepath: filepath to an image that might contain a face.\n",
    "    :type image_filepath: str\n",
    "    \n",
    "    :return features_dict: a dict that has hash of the image as key and\n",
    "        facial features of the image as values.\n",
    "    :rtype features_dict: dict\n",
    "    '''\n",
    "    \n",
    "    # if pickle file not found, create empty dictionary\n",
    "    if not os.path.exists(pickle_filepath):\n",
    "        face_features_dict = {}\n",
    "    else:\n",
    "        face_features_dict = pickle.load(open(pickle_filepath, \"rb\"))\n",
    "    \n",
    "    # generate unique identifier of the image\n",
    "    image_hash = hash_image(image_filepath)\n",
    "    \n",
    "    # if the image is not already processed\n",
    "    if image_hash not in face_features_dict:\n",
    "        embedding = get_face_embedding(image_filepath)\n",
    "        skin_tones, _ = get_skin_tones(image_filepath)\n",
    "\n",
    "        face_features_dict[image_hash] = {\"embedding\": embedding,\n",
    "                                          \"skin_tones\": skin_tones,\n",
    "                                          \"image_filepath\": os.path.abspath(image_filepath)}\n",
    "    \n",
    "    pickle.dump(face_features_dict, open(pickle_filepath, \"wb\"))\n",
    "    \n",
    "    return face_features_dict\n",
    "\n",
    "def store_face_features_multiple(pickle_filepath, image_directory):\n",
    "    '''\n",
    "    Store the facial features for the images in the image directory.\n",
    "    \n",
    "    :param pickle_filepath: filepath to the pickle file that stores the facial features\n",
    "    :type pickle_filepath: str\n",
    "    \n",
    "    :param image_directory: filepath to a directory containing images.\n",
    "        The directory will be recursively walked through.\n",
    "    :type image_directory: str\n",
    "    \n",
    "    :return features_dict: a dict that has hash of the image as key and\n",
    "        facial features of the image as values.\n",
    "    :rtype features_dict: dict\n",
    "    '''\n",
    "    image_filepaths = []\n",
    "    \n",
    "    # recursively walk through the entire image directory\n",
    "    for root, subdirs, files in os.walk(image_directory):\n",
    "        for filename in files:\n",
    "            # if the file is an image, store the face features\n",
    "            if filename.split('.')[-1] in ['jpg', 'jpeg', 'png']:\n",
    "                image_filepaths.append(root + '/' + filename)\n",
    "    \n",
    "    # for all the images in the image directory, store the face_features\n",
    "    with tqdm(total=len(image_filepaths)) as progress_bar:\n",
    "        for image_filepath in image_filepaths:\n",
    "            progress_bar.set_description('Processing images')\n",
    "            features_dict = store_face_features_single(pickle_filepath, image_filepath)\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "    \n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "def delete_face_features(pickle_filepath, image_directory):\n",
    "    '''\n",
    "    Delete all the face features in the `pickle_filepath` but not in the `image_directory`.\n",
    "    '''\n",
    "    \n",
    "    # if pickle file not found, return None\n",
    "    if not os.path.exists(pickle_filepath):\n",
    "        return None\n",
    "    \n",
    "    # store image hashes of image in `image_directory`\n",
    "    image_hashes = []\n",
    "    \n",
    "    # recursively walk through the entire image directory\n",
    "    for root, subdirs, files in os.walk(image_directory):\n",
    "        for filename in files:\n",
    "            # if the file is an image, store the image hash\n",
    "            if filename.split('.')[-1] in ['jpg', 'jpeg', 'png']:\n",
    "                image_hash = hash_image(root + '/' + filename)\n",
    "                image_hashes.append(image_hash)\n",
    "    \n",
    "    face_features_dict = pickle.load(open(pickle_filepath, \"rb\"))\n",
    "    \n",
    "    for image_hash in face_features_dict.keys():\n",
    "        if image_hash not in image_hashes:\n",
    "            face_features_dict.pop(image_hash)\n",
    "    \n",
    "    pickle.dump(face_features_dict, open(pickle_filepath, \"wb\"))\n",
    "    \n",
    "    return face_features_dict\n",
    "\n",
    "def get_top_similar_faces(image_filepath, pickle_filepath, image_directory, top_n=5):\n",
    "    '''\n",
    "    Obtain the top few most similar faces\n",
    "    \n",
    "    :return most_similar_faces: the filepaths and similarity scores of the most similar faces\n",
    "    :rtype most_similar_faces: list of dict\n",
    "    '''\n",
    "    \n",
    "    most_similar_faces = []\n",
    "    \n",
    "    _ = delete_face_features(pickle_filepath, image_directory)\n",
    "    face_features_dict = store_face_features_multiple(pickle_filepath, image_directory)\n",
    "    \n",
    "    target_image_hash = hash_image(image_filepath)\n",
    "    target_embedding = face_features_dict[target_image_hash][\"embedding\"]\n",
    "    \n",
    "    if target_embedding is None:\n",
    "        print(f\"No face(s) detected in {image_filepath}\")\n",
    "        return most_similar_faces\n",
    "    \n",
    "    for image_hash in face_features_dict:\n",
    "        if image_hash == target_image_hash:\n",
    "            continue\n",
    "            \n",
    "        embedding = face_features_dict[image_hash][\"embedding\"]\n",
    "        \n",
    "        if embedding is None:\n",
    "            continue\n",
    "            \n",
    "        face_similarity = _get_face_similarity(embedding, target_embedding)\n",
    "        \n",
    "        most_similar_faces.append({'face_similarity_score': face_similarity,\n",
    "                                   'image_filepath': face_features_dict[image_hash]['image_filepath']})\n",
    "        \n",
    "        most_similar_faces = sorted(most_similar_faces, \n",
    "                                    key= lambda item: item['face_similarity_score'],\n",
    "                                    reverse=True)\n",
    "        most_similar_faces = most_similar_faces[:top_n]\n",
    "    \n",
    "    return most_similar_faces\n",
    "    \n",
    "    \n",
    "def get_top_similar_skins(image_filepath, pickle_filepath, image_directory, top_n=5):\n",
    "    '''\n",
    "    Obtain the top few most similar skins\n",
    "    \n",
    "    :return most_similar_faces: the filepaths and similarity scores of the most similar skins\n",
    "    :rtype most_similar_faces: list of dict\n",
    "    '''\n",
    "    \n",
    "    most_similar_faces = []\n",
    "    \n",
    "    _ = delete_face_features(pickle_filepath, image_directory)\n",
    "    face_features_dict = store_face_features_multiple(pickle_filepath, image_directory)\n",
    "    \n",
    "    target_image_hash = hash_image(image_filepath)\n",
    "    target_skin_tones = face_features_dict[target_image_hash][\"skin_tones\"]\n",
    "    \n",
    "    if target_skin_tones is None:\n",
    "        print(f\"No face(s) detected in {image_filepath}\")\n",
    "        return most_similar_faces\n",
    "    \n",
    "    for image_hash in face_features_dict:\n",
    "        skin_tones = face_features_dict[image_hash][\"skin_tones\"]\n",
    "        \n",
    "        if image_hash == target_image_hash or skin_tones is None:\n",
    "            continue\n",
    "            \n",
    "        skin_similarity = _get_skin_tone_similarity(skin_tones, target_skin_tones)\n",
    "        \n",
    "        most_similar_faces.append({'skin_similarity_score': skin_similarity,\n",
    "                                   'image_filepath': face_features_dict[image_hash]['image_filepath']})\n",
    "        \n",
    "        most_similar_faces = sorted(most_similar_faces, \n",
    "                                    key= lambda item: item['skin_similarity_score'],\n",
    "                                    reverse=True)\n",
    "        most_similar_faces = most_similar_faces[:top_n]\n",
    "    \n",
    "    return most_similar_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████████████████████████████████| 190/190 [00:06<00:00, 30.33it/s]\n"
     ]
    }
   ],
   "source": [
    "image_filepath_1 = '../images/miscellaneous/korean_female_face.jpeg'\n",
    "image_filepath_2 = '../images/miscellaneous/many-asian-male-faces.jpg'\n",
    "image_filepath_3 = '../images/miscellaneous/ditto.png'\n",
    "image_filepath_4 = '../images/politician_baey_yam_keng/00001.jpg'\n",
    "\n",
    "o1 = get_top_similar_faces(image_filepath=image_filepath_4,\n",
    "                           pickle_filepath='../backend/facial_features.pickle', \n",
    "                           image_directory='../images/', \n",
    "                           top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████████████████████████████████| 190/190 [00:06<00:00, 29.09it/s]\n"
     ]
    }
   ],
   "source": [
    "o2 = get_top_similar_skins(image_filepath=image_filepath_4,\n",
    "                           pickle_filepath='../backend/facial_features.pickle', \n",
    "                           image_directory='../images/', \n",
    "                           top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'skin_similarity_score': 0.9869281045751634,\n",
       "  'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\guitarist_andrew_foy\\\\00001.jpg'},\n",
       " {'skin_similarity_score': 0.9751633986928105,\n",
       "  'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\influencer_jensen_tung\\\\01541.jpg'},\n",
       " {'skin_similarity_score': 0.9705882352941176,\n",
       "  'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\influencer_jensen_tung\\\\01831.jpg'},\n",
       " {'skin_similarity_score': 0.9640522875816994,\n",
       "  'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\influencer_jensen_tung\\\\02068.jpg'},\n",
       " {'skin_similarity_score': 0.9575163398692811,\n",
       "  'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\politician_dr_wan_azizah_wan_ismail\\\\00791.jpg'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\guitarist_andrew_foy\\\\00001.jpg',\n",
      "  'skin_similarity_score': 0.9869281045751634},\n",
      " {'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\influencer_jensen_tung\\\\01541.jpg',\n",
      "  'skin_similarity_score': 0.9751633986928105},\n",
      " {'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\influencer_jensen_tung\\\\01831.jpg',\n",
      "  'skin_similarity_score': 0.9705882352941176},\n",
      " {'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\influencer_jensen_tung\\\\02068.jpg',\n",
      "  'skin_similarity_score': 0.9640522875816994},\n",
      " {'image_filepath': 'C:\\\\Users\\\\tay.yq.XTRAMAN\\\\Documents\\\\GitHub\\\\facial-recognition\\\\images\\\\politician_dr_wan_azizah_wan_ismail\\\\00791.jpg',\n",
      "  'skin_similarity_score': 0.9575163398692811}]\n"
     ]
    }
   ],
   "source": [
    "print(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results_filename = 'results_' + datetime.today().strftime('%Y_%m_%d_%H_%M_%S') + '.txt' \n",
    "\n",
    "with open(results_filename, 'w') as f:\n",
    "    f.write(f'Most similar faces for {image_filepath_4}\\n\\n')\n",
    "    f.writelines(pprint.pformat(o1) + '\\n')\n",
    "    f.write('-'*100 + '\\n')\n",
    "    f.write(f'Most similar skin tone for {image_filepath_4}\\n\\n')\n",
    "    f.writelines(pprint.pformat(o2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0.9'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-4124b3c58521>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0.9'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '0.9'"
     ]
    }
   ],
   "source": [
    "int('0.9')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
